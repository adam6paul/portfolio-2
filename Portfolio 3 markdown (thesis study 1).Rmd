---
title: "Portfolio 4 MAP test- Thesis study 1"
author: "Adam Paul"
date: "3/24/2022"
output: html_document
---

> The purpose of this portfolio is to run the analyses for study 1 of my thesis. It is based on the analyses set up in Portfolio 4 (yes, the numbering is odd too me two).

Yes, that was a joke.

## Set-up

The main packages I need are lavaan and lmertest, but semPlot is used to create a visual model. The rest of the libraries are to ensure I have the other programs I may need.


library('psych')
library('reshape2')
library('dplyr')
library('lavaan')
library('Rcpp')
library('lme4')
library('lmerTest')
library('OpenMx')
library('semPlot')
library('tidyverse')
rm(list=ls())

##### Bringing in the data

Data downloaded from Qualtrics as a .csv

```{r bringing in data}
study1 <- read.csv("~/Master's Program Wake Forest/Research/Online Belonging/Thesis Study 1/Online Course Experiences (Excel cleaned).csv", row.names=NULL, stringsAsFactors=TRUE)
View(study1)
```


##TEMP CHANGE
Variable cleaning was done using SPSS, which is not what I wanted to do. As such, the data will be returned from SPSS. Full version will have data cleaning done in R.

```{r temporary data returning}
`study1` <- read.csv("~/Master's Program Wake Forest/Research/Online Belonging/Thesis Study 1/Online Course Experiences (SPSS cleaned).csv")
View(study1)
```

Ensuring the dataframe is a tibble (be proud, Mason)

as_tibble(study1)

### Checking for bad data

Checking for bad actors in the data, before giving credit.

summary(study1$duration_seconds)

```{r Filtering}
#looking narrowly at people under the 1st quartile (172)

filter(study1, duration_seconds < 172) %>%
        arrange(duration_seconds)
```

I found no straight-lining within this subset, which suggests to me that the data was all given in good faith. However, I wanted to look at another subset.

I filtered for students that answered positively on two items that previous research suggest should be opposite, belonging and feeling like an outsider.

```{r}
filter(study1, school_belong > 4, school_outsider > 4)
#40 students fall into this category

filter(study1, class_belong > 4, class_outsider > 4)
#18 students fall into class.

filter(study1, school_belong > 4, school_outsider > 4, class_belong > 4, class_outsider > 4)
#4 students fall into this category. Only one seemed suspicious, but passed along to Shannon to make a decision.

```

## Data cleaning

Removing identifying information from the dataset.

```{r}
study1 <- subset(study1, select= -c(StartDate, EndDate, Status,	IPAddress, Progress,
                Finished, RecordedDate, ResponseId, RecipientLastName, RecipientFirstName,
                RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude,
                DistributionChannel, UserLanguage))

```


##### Basic data cleaning

Several variable names were changed in excel. Specifically, the names of the gender responses were changed from a number to their actual gender identity (e.g., demog_gender_1 became demog_gender_female). Will make a full-list when I re-do the data cleaning in R.


------------------

# MEDIATION MODEL DETAILS

------------------

> This section is information given to me by Shannon, kept here and in other path analysis portfolios so I have access to them.

Reminder: Rules of thumb to evaluate goodness of fit: CFI/TLI > 0.95, RMSEA < 0.05, SRMR < 0.06  (Reference: Hu & Bentler, 1999)

### References: 
> http://davidakenny.net/cm/fit.htm
 https://www.psychologie.uzh.ch/dam/jcr:ffffffff-b371-2797-0000-00000fda8f29/chisquare_diff_en.pdf
 Chi-Square Distribution Table: http://sites.stat.psu.edu/~mga/401/tables/Chi-square-table.pdf
 http://www.structuralequations.com/resources/Basic_lavaan_Syntax_Guide_Aug1_2013.pdf

------------------

# Current settings 

------------------

### Resampling 
 Right now, bootstraps are set at 1000 resamples. This to make running the script not take impossibly long
 When running final models, 10000 resamples would probably be preferred - but it'll take a while. 

### Type of CIs
 lavaan can handle four types of bootstrapped CIs; add "boot.ci.type = " to parameterEstimates
 options for types are "norm", "basic", "perc" (percentile), and "bca.simple" 
 defualt is "perc" (I think )

### Significance Levels
 alpha level for bootstrapping can be adjusted; add "level = " to parameterEstimates 
 options for levels are e.g., "95", "99"

------------------

## Analyses!

------------------

##### Hypotheses

H1: Students who disclose in a class or small group will report higher feelings of belonging in the class and at their institution.

H2: Prompting disclosure in class or in small groups will be associated with greater disclosure and greater sense of belonging at the classroom and institutional level, as well as whether the relationship between disclosure and institutional belonging is mediated by classroom belonging.

All of this can be answered with a single path analysis, but before getting there I need to do some basic examinations of the data.


Looking at the basic information for class disclosure.

```{r}
summary(study1$class_belong_comp4)
summary(study1$school_belong_comp4)
summary(study1$cdiscl_prompt_comp2)
summary(study1$class_disclose_comp2)
summary(study1$group_disclose_comp2)
summary(study1$gdiscl_prompt_comp2)

```



#### Creating the model!

Now that we have an understanding of the data, it's time to move on to the model.

>These are the covariates I am including in the model:
Gender, with female as the reference class: 
        gender_identity_dich 
Race, with white as the reference class: 
        race_asian race_black race_hispanic race_multiracial 
Classmates and group members known prior:
        classmates_know groupdesc_know_prior


##### Model 1
```{r model creation}
model_1 <-   '  #Class Belonging direct effects
                class_belong_comp4 ~ a*class_disclose_comp2 + gender_nonbinary +                             gender_male_dummy + race_asian + race_black + race_hispanic +                                race_multiracial + class_know_prior + know_prior_group
                
                class_belong_comp4 ~ b*group_disclose_comp2
                
                #School Belonging direct effects
                school_belong_comp4 ~ c*class_disclose_comp2 + gender_nonbinary +                            gender_male_dummy + race_asian + race_black + race_hispanic +                                race_multiracial + class_know_prior + know_prior_group
                
                school_belong_comp4 ~ d*group_disclose_comp2
                
                #Mediator for class disclosure
                class_disclose_comp2 ~ e*cdiscl_prompt_comp2
                class_belong_comp4 ~ cdiscl_prompt_comp2
                school_belong_comp4 ~ cdiscl_prompt_comp2
                
                #Mediator for group disclosure
                group_disclose_comp2 ~ f*gdiscl_prompt_comp2
                class_belong_comp4 ~ gdiscl_prompt_comp2
                school_belong_comp4 ~ gdiscl_prompt_comp2
                
                #removing correlation between prompted disclosures
                cdiscl_prompt_comp2 ~~ 0*gdiscl_prompt_comp2
                '
```

#### Testing the fit

```{r testing fit}
fit <- sem(model_1, data=study1)

summary(fit, fit.measures=TRUE, standardize=TRUE, rsquare=TRUE)

```

> Key variables and significant variables
class belonging
     class disclosure 	est.   .189	p=.126
     Group disclosure	est.   .065	p=.649
     nonbinary 		est. -1.069	p=.058
     asian		est. -1.037	p=.004
     class_know_prior	est.   .479	p=.001
     group_know_prior	est.   .065	p=.065
school belonging
     class disclosure	est. -0.144 	p=.170
     group disclosure   est.   .221	p=.017
     nonbinary		est.  -.532	p=.269
     asian		est.  -.676	p=.027
     class know prior	est.   .297	p=.014
     group_know_prior	est.  -.122	p=.261


We replicated our finding that Asian student status is a negative predictor of belonging. While marginal for class belonging, non binary is also a negative predictor.

class members known prior is a predictor of belonging and group members known is marginal.

I'd like to briefly look at whether international student status is a predictor. 
#For some reason, this code is wrong?

```{r model 1a}
model_1a <-   '  #Class Belonging direct effects
                class_belong_comp4 ~ a*class_disclose_comp2 + gender_nonbinary +                             gender_male_dummy + race_asian + race_black + race_hispanic +                                
                race_multiracial + class_know_prior + know_prior_group + demog_international
                
                class_belong_comp4 ~ b*group_disclose_comp2
                
                #School Belonging direct effects
                school_belong_comp4 ~ c*class_disclose_comp2 + gender_nonbinary +                            gender_male_dummy + race_asian + race_black + race_hispanic +                                
                race_multiracial + class_know_prior + know_prior_group + demog_international
                
                school_belong_comp4 ~ d*group_disclose_comp2
                
                #Mediator for class disclosure
                class_disclose_comp2 ~ e*cdiscl_prompt_comp2
                class_belong_comp4 ~ cdiscl_prompt_comp2
                school_belong_comp4 ~ cdiscl_prompt_comp2
                
                #Mediator for group disclosure
                group_disclose_comp2 ~ f*gdiscl_prompt_comp2
                class_belong_comp4 ~ gdiscl_prompt_comp2
                school_belong_comp4 ~ gdiscl_prompt_comp2
                
                #removing correlation between prompted disclosures
                cdiscl_prompt_comp2 ~~ 0*gdiscl_prompt_comp2'
```


```{r testing fit}
fit <- sem(model_1a, data=study1)

summary(fit, fit.measures=TRUE, standardize=TRUE, rsquare=TRUE)

```


> Class disclosure is not predicting class belonging or school belonging, which is odd. So I want to find out why.





##### Possibility 1! Low Disclosure

This may be because people are mostly at a 1 in disclosure.

```{r looking at disclosure}
#Looking at the numbers
study1 %>%
        group_by(class_disclose_comp2) %>%
        summarize(freq=n())
#111 at 1, 32 at 1.5, and 88 at 2; or 77% of the sample. 

#Just looking at the distribution of disclosure
hist(study1$class_disclose_comp2)

#Graphing the relationship between class disclosure and class belonging.
plot(study1$class_disclose_comp2, study1$class_belong_comp4)

study1 %>%
        group_by(class_disclose_comp2) %>%
        summarize(mean(class_belong_comp4))
```

In our sample, 231 participants have disclosure lower than 2 on our composite variable. Additionally, looking at the graph shows that there is pretty substantial variance within the lowest level of disclosure.


```{r looking closer at the disclosure levels}
study1 %>%
        group_by(cdiscl_private) %>%
        summarize(freq=n())
#132 are at 1 (Never), and 118 are at 2 (Rarely); or 83% of our sample

study1 %>%
        group_by(cdiscl_self_talk) %>%
        summarize(freq=n())
#127 at 1, 108 at 2; 78% of our sample
```

As expected, a large portion of our participants are not reporting any disclosure. Looking at some responses on an open-ended comment, several students indicated they were in wholly asynchronous classes. We should have expected this and controlled for it, but we can look at exploratory analyses with this in mind now.

We suspect that asynchronous classes have disrupted our data.

And so, we will run the model again, but this time dropping anyone who has no disclosure at all. While this does eliminate a key segment of data, it will allow us to look at only classes that are not wholly asynchronous.


```{r running with only people who have some disclosure}
study1a <- study1[study1$class_disclose_comp2 > 1,]
```


```{r testing fit}
fit <- sem(model_1, data=study1a)

summary(fit, fit.measures=TRUE, standardize=TRUE, rsquare=TRUE)

```

While we lost a LOT of participants, leaving us with a sample of only n=83, we do see that when we remove people whom have no disclosure there is a relationship between class disclosure and school belonging. The relationship between class belonging for both variables remains non-significant.

  >class Belonging                                                        
     Class disclosure   Est= -0.059     SE=0.143        p=0.681
     Group disclosure   Est=0.100       SE=0.121        p=0.410
   School Belonging
     Class disclosure   Est=-0.380      SE=0.123        p=0.002
     Group disclosure   Est=0.272       SE=0.104        p=0.009




##### Possibility 2! Lost data

Looking at the results from model_1, we're also losing a lot of our sample. This may be because it's excluding anyone who did not use a group, as they have no data on group disclosure. I examine this possibility below.

```{r}
study1 %>%
        group_by(group_use) %>%
        summarize(freq=n())
#Most people are saying they don't use groups at all (123 with no usage).
```

The graph makes it clear that there's pretty wide variance for the people with no class disclosure. That may be stifling the variance among people who do disclose from appearing in the model.

So now, we want to look at what's happening without group disclosure.


##### Model 2

While model_1 is good, it is washing out a lot of data from the class disclosure as we only got responses for group disclosure from students who did meet in groups. As such, we're interested in examining the full class disclosure data set.

```{r no group disclosure model}
model_2 <-   '  #Class Belonging direct effects
                class_belong_comp4 ~ a*class_disclose_comp2 + gender_nonbinary +                             gender_male_dummy + race_asian + race_black + race_hispanic +                                race_multiracial + class_know_prior
                
                #School Belonging direct effects
                school_belong_comp4 ~ c*class_disclose_comp2 + gender_nonbinary +                            gender_male_dummy + race_asian + race_black + race_hispanic +                                race_multiracial + class_know_prior
                
                #Mediator for class disclosure
                class_disclose_comp2 ~ e*cdiscl_prompt_comp2
                class_belong_comp4 ~ cdiscl_prompt_comp2
                school_belong_comp4 ~ cdiscl_prompt_comp2
                '
```

```{r testing fit}
fit <- sem(model_2, data=study1)

summary(fit, fit.measures=TRUE, standardize=TRUE, rsquare=TRUE)

```

Class disclosure is predictive of class belonging, but not of institutional belonging.

> Key variable
                         Estimate  Std.Err  z-value  P(>|z|)
  Class belonging                                                      
    class disclosure       0.325    0.096    3.377    0.001
  school belonging                                                      
    class disclosure       0.114    0.085    1.334    0.182
    
With the larger sample we're able to see the pattern that we expected. 


#### Graphing!

It's important to get a visual understanding of what the data is telling us, even if the model is pretty ugly right now. I will work with Mason to get a pretty visualization.

```{r Path visualization}
semPaths(fit, whatLabels="par", layout="tree", nCharNodes=0, sizeMan=12, sizeMan2=6)
```

#### Bootstrapping

#####for boot strapped 95% CIs

```{r bootstrapped code}
fit <- sem(model_1, data=Classroom_Experiences, se="bootstrap", bootstrap = 10000)
summary(fit, fit.measures=TRUE, standardize=TRUE, rsquare=TRUE)
```


# What does the data mean?

>This section will be used for me to write up what I've learned from the data analysis, as a point to reference the findings while I'm working later.

>H1: Students who disclose in a class or small group will report higher feelings of belonging in the class and at their institution.

XXXXXXXXXXXXXXXXXXXXXXXX

>H2: Prompting disclosure in class or in small groups will be associated with greater disclosure and greater sense of belonging at the classroom and institutional level, as well as whether the relationship between disclosure and institutional belonging is mediated by classroom belonging.

XXXXXXXXXXXXXXXXXXXXXXXX